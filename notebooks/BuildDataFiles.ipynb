{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "687a5be4",
   "metadata": {},
   "source": [
    "# Configure KBase Jupyter Dev Environment\n",
    "<sub><sup>(contact chenry@anl.gov with questions)</sub></sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced60d40-9b5b-484e-b688-e0aa2c50144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "print(\"python version \" + platform.python_version())\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import re\n",
    "\n",
    "sys.path = [os.environ.get(\"CODE_BASE\",\"/scratch/shared/code\")+\"/chenry_utility_module/lib\"] + sys.path\n",
    "from chenry_utility_module.kbdevutils import KBDevUtils\n",
    "kbdevutil = KBDevUtils(\"ModelSEED2\")\n",
    "\n",
    "from modelseedpy import ModelSEEDBiochem\n",
    "from modelseedpy.core.mstemplate import MSTemplateBuilder\n",
    "from modelseedpy.core.annotationontology import convert_to_search_role,split_role\n",
    "from modelseedpy.helpers import get_template\n",
    "import cobra\n",
    "import cobrakbase\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "msrecon = kbdevutil.msseedrecon()\n",
    "annoapi = kbdevutil.anno_client(native_python_api=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b4fda7",
   "metadata": {},
   "source": [
    "# Identifying filter reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700ae84-58a7-459d-81dd-65511f7f20cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbase_api = msrecon.kbase_api\n",
    "template = msrecon.get_template(msrecon.templates[\"gramneg\"])\n",
    "biochem = ModelSEEDBiochem.get()\n",
    "filter_df = [] \n",
    "no_form = {}\n",
    "allowed = [\"cpd11416\"]\n",
    "for compound in biochem.compounds:\n",
    "    if str(compound.formula) == \"nan\" and compound.id not in allowed:\n",
    "        no_form[compound.id+\"_0\"] = 1\n",
    "print(len(no_form))\n",
    "count = 0\n",
    "for reaction in biochem.reactions:\n",
    "    reason = None\n",
    "    if re.search(\"MI\", reaction.status) != None:\n",
    "        reason = \"MI\"\n",
    "    elif re.search(\"CI\", reaction.status) != None and reaction.id+\"_c\" not in template.reactions:\n",
    "        reason = \"CI\"\n",
    "    elif reaction.is_obsolete == True:\n",
    "        reason = \"OBS\"\n",
    "    elif len(reaction.metabolites) == 0:\n",
    "        reason = \"Empty\"\n",
    "    else:\n",
    "        for met in reaction.metabolites:\n",
    "            if met.id in no_form:\n",
    "                reason = \"NOFORM\"\n",
    "                break\n",
    "            if met.smiles and \"*\" in met.smiles:\n",
    "                reason = \"Abstract\"\n",
    "                break\n",
    "    if reason != None:\n",
    "        if reason in [\"MI\",\"CI\",\"OBS\",\"EMPTY\"] or reaction.id not in template.reactions:\n",
    "            filter_df.append({\n",
    "                \"id\":reaction.id,\n",
    "                \"reason\":reason\n",
    "            })\n",
    "df = pd.DataFrame.from_records(filter_df)\n",
    "df.to_csv(\"/scratch/shared/code/cb_annotation_ontology_api/data/FilteredReactions.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1d5bdf",
   "metadata": {},
   "source": [
    "# Updating ModelSEED reaction obsolete reaction aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9405267a-b3cf-4540-804c-d0bd121628d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "biochem = ModelSEEDBiochem.get()\n",
    "ModelSEED_reaction_hash = {}\n",
    "for rxn in biochem.reactions:\n",
    "    if rxn.is_obsolete:\n",
    "        ModelSEED_reaction_hash[rxn.id] = []\n",
    "        if \"modelseed\" in rxn.aliases:\n",
    "            ModelSEED_reaction_hash[rxn.id].append(rxn.aliases[\"modelseed\"])\n",
    "        \n",
    "with open('/scratch/shared/code/cb_annotation_ontology_api/data/msrxn_hash.json', 'w') as outfile:\n",
    "    json.dump(ModelSEED_reaction_hash, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb24d06",
   "metadata": {},
   "source": [
    "# Update SSO and reaction SSO mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae69621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_sso = False\n",
    "#Getting current template object\n",
    "template = msrecon.get_template(msrecon.templates[\"gramneg\"])\n",
    "#Getting SSO ontology object\n",
    "sso = msrecon.kbase_api.get_object(\"seed_subsystem_ontology\",\"KBaseOntology\")\n",
    "\n",
    "#Pulling all roles\n",
    "role_hash = dict()\n",
    "with open('/scratch/shared/data/TemplateFunctions/core.2015-2020.json') as json_file:\n",
    "    role_hash = json.load(json_file)\n",
    "unique_role_hash = {}\n",
    "consolidated_roles = {}\n",
    "for role_set in role_hash:\n",
    "    for role in role_hash[role_set]:\n",
    "        role_hash[role_set][role] = re.sub(\"=>.+\",\"\",role_hash[role_set][role])\n",
    "        roles = split_role(role_hash[role_set][role])\n",
    "        for fr in roles:\n",
    "            if fr not in unique_role_hash:\n",
    "                unique_role_hash[fr] = []\n",
    "            unique_role_hash[fr].append(role_set)\n",
    "            searchname = convert_to_search_role(fr)\n",
    "            if searchname not in consolidated_roles:\n",
    "                consolidated_roles[searchname] = {\"roles\":{},\"sso\":None,\"rxn\":{},\"subsys\":None,\"source\":\"seed\"}\n",
    "            if role_set == \"core.2020-0417\":\n",
    "                consolidated_roles[searchname][\"source\"] = \"latest\"\n",
    "            consolidated_roles[searchname][\"roles\"][fr] = 1\n",
    "\n",
    "#Parsing SSO ontology\n",
    "largest_term = None\n",
    "sso_hash = dict()\n",
    "for term in sso[\"term_hash\"]:\n",
    "    name = convert_to_search_role(sso[\"term_hash\"][term][\"name\"])\n",
    "    if name not in consolidated_roles:\n",
    "        consolidated_roles[name] = {\"roles\":{},\"sso\":None,\"rxn\":{},\"subsys\":None,\"source\":\"sso\"}\n",
    "    consolidated_roles[name][\"sso\"] = term\n",
    "    consolidated_roles[name][\"roles\"][sso[\"term_hash\"][term][\"name\"]] = 1\n",
    "    if largest_term == None or term > largest_term:\n",
    "        largest_term = term\n",
    "    sso_hash[term] = sso[\"term_hash\"][term][\"name\"]\n",
    "\n",
    "#Parsing new template\n",
    "rxn_hash = {}\n",
    "for reaction in template.reactions:\n",
    "    for cpx in reaction.complexes:\n",
    "        for role in cpx.roles:\n",
    "            rxnid = re.sub(\"_[a-z]\",\"\",reaction.id)\n",
    "            rolename = convert_to_search_role(role.name)\n",
    "            if rolename not in consolidated_roles:\n",
    "                consolidated_roles[rolename] = {\"roles\":{},\"sso\":None,\"rxn\":{},\"subsys\":None,\"source\":\"template\"}\n",
    "            consolidated_roles[rolename][\"roles\"][role.name] = 1       \n",
    "            consolidated_roles[rolename][\"rxn\"][rxnid] = 1\n",
    "            if rxnid not in rxn_hash:\n",
    "                rxn_hash[rxnid] = {}\n",
    "            rxn_hash[rxnid][rolename] = cpx.id\n",
    "\n",
    "#Issuing new SSO IDs and saving new SSO rxn mapping\n",
    "if create_new_sso:\n",
    "    largest_term = re.sub(\"SSO:\",\"\",largest_term)\n",
    "    largest_term = int(largest_term)\n",
    "    for name in consolidated_roles:\n",
    "        if consolidated_roles[name][\"sso\"] == None:\n",
    "            if len(consolidated_roles[name][\"rxn\"].keys()) > 0 or consolidated_roles[name][\"source\"] == \"latest\":\n",
    "                largest_term += 1\n",
    "                newsso = \"SSO:\"\n",
    "                zeros = 9 - len(str(largest_term))\n",
    "                for x in range(zeros):\n",
    "                    newsso += \"0\"\n",
    "                newsso += str(largest_term)\n",
    "                keylist = list(consolidated_roles[name][\"roles\"].keys())\n",
    "                consolidated_roles[name][\"sso\"] = newsso\n",
    "                sso_hash[newsso] = keylist[0]\n",
    "            \n",
    "    new_sso = {\n",
    "        \"format_version\" : \"0.1\",\n",
    "        \"default_namespace\" : \"seed_subsystem_ontology\",\n",
    "        \"ontology\" : \"sso\",\n",
    "        \"data_version\" : \"releases/2020-04-17\",\n",
    "        \"term_hash\" : {}\n",
    "    }\n",
    "\n",
    "    for term in sso_hash:\n",
    "        new_sso[\"term_hash\"][term] = {\n",
    "            \"id\" : term,\n",
    "            \"name\" : sso_hash[term]\n",
    "        }\n",
    "\n",
    "    with open(\"/scratch/shared/code/cb_annotation_ontology_api/data/new_sso.json\", 'w') as outfile:\n",
    "        json.dump(new_sso, outfile, indent=2)\n",
    "\n",
    "sso_rxns = {}\n",
    "for name in consolidated_roles:\n",
    "    if len(consolidated_roles[name][\"rxn\"].keys()) > 0:\n",
    "        if consolidated_roles[name][\"sso\"]:\n",
    "            sso_rxns[consolidated_roles[name][\"sso\"]] = list(consolidated_roles[name][\"rxn\"].keys())\n",
    "with open(\"/scratch/shared/code/cb_annotation_ontology_api/data/new_SSO_reactions.json\", 'w') as outfile:\n",
    "    json.dump(sso_rxns, outfile, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90f4a2b",
   "metadata": {},
   "source": [
    "# Printing Obsolete EC numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88d697b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Parse the XML file\n",
    "tree = ET.parse(\"/scratch/shared/data/ECOntology/enzyme-data.xml\")\n",
    "root = tree.getroot()\n",
    "root = root[0]\n",
    "ec_hash = {}\n",
    "for child in root:\n",
    "    if child.attrib[\"name\"] == \"hist\" and child.tag == \"table_data\":\n",
    "        root = child\n",
    "        break\n",
    "for row in root:\n",
    "    data = {}\n",
    "    for child in row:\n",
    "        data[child.attrib[\"name\"]] = child.text\n",
    "    ec_hash[data[\"ec_num\"]] = data\n",
    "obsolete_ec = {}\n",
    "for ec in ec_hash:\n",
    "    if ec_hash[ec][\"action\"] == \"transferred\" or ec_hash[ec][\"action\"] == \"deleted\":\n",
    "        match = re.search(r'(\\d+\\.[\\d-]+\\.[\\d-]+\\.[\\d-]+)',ec_hash[ec][\"note\"])\n",
    "        if match:\n",
    "            if ec not in obsolete_ec:\n",
    "                obsolete_ec[ec] = match.group(0)\n",
    "with open(\"/scratch/shared/code/cb_annotation_ontology_api/data/obsolete_ec.json\", 'w') as outfile:\n",
    "    json.dump(obsolete_ec, outfile, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_ModelSEED",
   "language": "python",
   "name": "python3_modelseed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
